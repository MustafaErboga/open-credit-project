"""
ADIM 1: Veri TanÄ±lama - Neden 0.80'i GeÃ§emiyoruz?
Bu script veriyi derinlemesine analiz eder ve sorunlarÄ± tespit eder.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder

print("="*60)
print("VERÄ° TANILAMASI - SORUN TESPÄ°TÄ°")
print("="*60)

# Veriyi yÃ¼kle
try:
    df = pd.read_csv("data/cleaned_credit.csv")
    print(f"\nâœ… Veri yÃ¼klendi: {df.shape}")
except FileNotFoundError:
    print("\nâŒ cleaned_credit.csv bulunamadÄ±!")
    print("LÃ¼tfen veri dosyanÄ±zÄ± data/ klasÃ¶rÃ¼ne koyun.")
    exit(1)

# 1. Temel Ä°statistikler
print("\n" + "="*60)
print("1. TEMEL Ä°STATÄ°STÄ°KLER")
print("="*60)
print(f"Toplam SatÄ±r: {len(df):,}")
print(f"Toplam SÃ¼tun: {len(df.columns)}")
print(f"Bellek KullanÄ±mÄ±: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")

# 2. Eksik Veri KontrolÃ¼
print("\n" + "="*60)
print("2. EKSÄ°K VERÄ° ANALÄ°ZÄ°")
print("="*60)
missing = df.isnull().sum()
missing_pct = (missing / len(df)) * 100
missing_df = pd.DataFrame({
    'Eksik SayÄ±': missing,
    'YÃ¼zde (%)': missing_pct
})
missing_df = missing_df[missing_df['Eksik SayÄ±'] > 0].sort_values('Eksik SayÄ±', ascending=False)

if len(missing_df) > 0:
    print("âš ï¸  SORUN: Eksik veriler var!")
    print(missing_df)
else:
    print("âœ… Eksik veri yok")

# 3. Hedef DeÄŸiÅŸken DaÄŸÄ±lÄ±mÄ±
print("\n" + "="*60)
print("3. HEDEF DEÄÄ°ÅKEN DENGESÄ° (Credit_Score)")
print("="*60)
if 'Credit_Score' in df.columns:
    target_dist = df['Credit_Score'].value_counts()
    target_pct = (target_dist / len(df)) * 100
    
    print("\nDaÄŸÄ±lÄ±m:")
    for class_name, count in target_dist.items():
        pct = target_pct[class_name]
        print(f"  {class_name}: {count:,} ({pct:.1f}%)")
    
    # Class imbalance kontrolÃ¼
    max_pct = target_pct.max()
    min_pct = target_pct.min()
    imbalance_ratio = max_pct / min_pct
    
    if imbalance_ratio > 2:
        print(f"\nâš ï¸  SORUN: Class Imbalance var! Oran: {imbalance_ratio:.2f}x")
        print("   â†’ Ã‡Ã¶zÃ¼m: SMOTE veya class_weight kullanÄ±n")
    else:
        print(f"\nâœ… Class dengesi iyi (Oran: {imbalance_ratio:.2f}x)")
else:
    print("âŒ Credit_Score sÃ¼tunu bulunamadÄ±!")

# 4. Veri Tipleri
print("\n" + "="*60)
print("4. VERÄ° TÄ°PÄ° ANALÄ°ZÄ°")
print("="*60)
dtype_counts = df.dtypes.value_counts()
print("\nVeri Tipleri:")
for dtype, count in dtype_counts.items():
    print(f"  {dtype}: {count} sÃ¼tun")

# Numeric olmayan ama numeric olmasÄ± gereken sÃ¼tunlarÄ± bul
print("\nProblematik SÃ¼tunlar (object tipi ama sayÄ±sal olabilir):")
problematic = []
for col in df.select_dtypes(include=['object']).columns:
    if col != 'Credit_Score':  # Hedef deÄŸiÅŸkeni pas geÃ§
        # Ä°lk birkaÃ§ deÄŸere bak
        sample = df[col].dropna().head(100)
        # SayÄ±ya Ã§evrilebilir mi?
        try:
            pd.to_numeric(sample, errors='coerce')
            numeric_ratio = sample.apply(lambda x: str(x).replace('.','').replace('-','').isdigit()).sum() / len(sample)
            if numeric_ratio > 0.5:
                problematic.append(col)
                print(f"  âš ï¸  {col}: %{numeric_ratio*100:.0f} sayÄ±sal gÃ¶rÃ¼nÃ¼yor ama object!")
        except:
            pass

if not problematic:
    print("  âœ… TÃ¼m veri tipleri uygun")

# 5. Outlier Analizi (sadece numeric sÃ¼tunlar)
print("\n" + "="*60)
print("5. OUTLIER (AYKIRI DEÄER) ANALÄ°ZÄ°")
print("="*60)
numeric_cols = df.select_dtypes(include=[np.number]).columns
outlier_summary = []

for col in numeric_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    outliers = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()
    outlier_pct = (outliers / len(df)) * 100
    
    if outlier_pct > 5:  # %5'ten fazla outlier varsa
        outlier_summary.append({
            'SÃ¼tun': col,
            'Outlier SayÄ±': outliers,
            'YÃ¼zde (%)': outlier_pct
        })

if outlier_summary:
    print("âš ï¸  SORUN: YÃ¼ksek oranda outlier var!")
    outlier_df = pd.DataFrame(outlier_summary).sort_values('YÃ¼zde (%)', ascending=False)
    print(outlier_df.to_string(index=False))
    print("\n   â†’ Ã‡Ã¶zÃ¼m: Winsorization veya capping uygulayÄ±n")
else:
    print("âœ… Outlier oranÄ± kabul edilebilir seviyede")

# 6. Korelasyon Analizi
print("\n" + "="*60)
print("6. KORELASYON ANALÄ°ZÄ°")
print("="*60)

# Target'Ä± encode et
if 'Credit_Score' in df.columns:
    df_corr = df.copy()
    le = LabelEncoder()
    df_corr['Credit_Score_Encoded'] = le.fit_transform(df_corr['Credit_Score'])
    
    # Sadece numeric sÃ¼tunlarla korelasyon
    numeric_df = df_corr.select_dtypes(include=[np.number])
    
    if 'Credit_Score_Encoded' in numeric_df.columns:
        target_corr = numeric_df.corr()['Credit_Score_Encoded'].drop('Credit_Score_Encoded')
        target_corr = target_corr.abs().sort_values(ascending=False)
        
        print("\nEn YÃ¼ksek Korelasyonlu Ã–zellikler (Top 10):")
        print(target_corr.head(10))
        
        # DÃ¼ÅŸÃ¼k korelasyonlu Ã¶zellikler
        low_corr = target_corr[target_corr < 0.05]
        if len(low_corr) > 0:
            print(f"\nâš ï¸  SORUN: {len(low_corr)} sÃ¼tun Ã§ok dÃ¼ÅŸÃ¼k korelasyona sahip (<0.05)")
            print("   DÃ¼ÅŸÃ¼k korelasyonlu sÃ¼tunlar:", low_corr.index.tolist()[:5])
            print("   â†’ Ã‡Ã¶zÃ¼m: Bu sÃ¼tunlarÄ± kaldÄ±rÄ±n veya feature engineering yapÄ±n")

# 7. Kardinalite KontrolÃ¼ (Kategorik deÄŸiÅŸkenler)
print("\n" + "="*60)
print("7. KATEGORÄ°K DEÄÄ°ÅKEN ANALÄ°ZÄ°")
print("="*60)
categorical_cols = df.select_dtypes(include=['object']).columns
high_cardinality = []

for col in categorical_cols:
    if col != 'Credit_Score':
        unique_count = df[col].nunique()
        unique_ratio = unique_count / len(df)
        
        if unique_ratio > 0.5:  # %50'den fazla unique deÄŸer
            high_cardinality.append({
                'SÃ¼tun': col,
                'Unique SayÄ±': unique_count,
                'Unique Oran': f"{unique_ratio*100:.1f}%"
            })

if high_cardinality:
    print("âš ï¸  SORUN: YÃ¼ksek kardinaliteli kategorik sÃ¼tunlar var!")
    hc_df = pd.DataFrame(high_cardinality)
    print(hc_df.to_string(index=False))
    print("\n   â†’ Ã‡Ã¶zÃ¼m: Target encoding veya frequency encoding kullanÄ±n")
else:
    print("âœ… Kategorik deÄŸiÅŸkenler uygun kardinaliteye sahip")

# 8. Ã–zellik SayÄ±sÄ±
print("\n" + "="*60)
print("8. Ã–ZELLÄ°K SAYISI ANALÄ°ZÄ°")
print("="*60)
feature_count = len(df.columns) - 1  # Credit_Score hariÃ§
print(f"Toplam Ã–zellik SayÄ±sÄ±: {feature_count}")

if feature_count < 10:
    print("âš ï¸  SORUN: Ã‡ok az Ã¶zellik var!")
    print("   â†’ Ã‡Ã¶zÃ¼m: Feature engineering ile yeni Ã¶zellikler tÃ¼retin")
elif feature_count > 50:
    print("âš ï¸  SORUN: Ã‡ok fazla Ã¶zellik var!")
    print("   â†’ Ã‡Ã¶zÃ¼m: Feature selection uygulayÄ±n")
else:
    print("âœ… Ã–zellik sayÄ±sÄ± uygun")

# 9. Ã–ZET ve Ã–NERÄ°LER
print("\n" + "="*60)
print("9. Ã–ZET ve Ã–NERÄ°LER")
print("="*60)

issues_found = []
if len(missing_df) > 0:
    issues_found.append("Eksik veriler var")
if 'Credit_Score' in df.columns and (target_pct.max() / target_pct.min()) > 2:
    issues_found.append("Class imbalance var")
if problematic:
    issues_found.append("YanlÄ±ÅŸ veri tipleri var")
if outlier_summary:
    issues_found.append("YÃ¼ksek oranda outlier var")

if issues_found:
    print("\nğŸ”´ Tespit Edilen Sorunlar:")
    for i, issue in enumerate(issues_found, 1):
        print(f"  {i}. {issue}")
    
    print("\nğŸ’¡ Ã–NERÄ°LER:")
    print("  1. Ã–nce veri temizliÄŸi yapÄ±n (02_data_cleaning.py)")
    print("  2. Feature engineering uygulayÄ±n (03_feature_engineering.py)")
    print("  3. Hyperparameter tuning yapÄ±n (04_hyperparameter_tuning.py)")
else:
    print("\nâœ… Veri kalitesi iyi gÃ¶rÃ¼nÃ¼yor!")
    print("   DoÄŸrudan feature engineering ve tuning'e geÃ§ebilirsiniz.")

print("\n" + "="*60)
print("TANILAIMA TAMAMLANDI")
print("="*60)